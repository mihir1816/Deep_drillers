{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LypF48waBcR7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI4kBF6uYGwX",
        "outputId": "f6d650b2-9a63-44da-832f-2a5e1e9101fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai python-docx PyPDF2 pdf2image pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kmcTqjjGYNnL"
      },
      "outputs": [],
      "source": [
        "# First install the required libraries:\n",
        "# pip install PyPDF2 pdf2image pytesseract pillow\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import re\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # For text-based PDFs (using PyPDF2)\n",
        "        reader = PdfReader(pdf_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    except Exception as e:\n",
        "        # For image-based PDFs (using OCR with pdf2image and pytesseract)\n",
        "        # Note: Ensure Tesseract OCR is installed on your system\n",
        "        # https://github.com/tesseract-ocr/tesseract#installing-tesseract\n",
        "        images = convert_from_path(pdf_path)\n",
        "        for img in images:\n",
        "            text += pytesseract.image_to_string(img)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove headers/footers using regex\n",
        "    text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YbAmi8uPZ4hO"
      },
      "outputs": [],
      "source": [
        "paper_text = extract_text_from_pdf(\"/content/Addressing_the_Productivity_Paradox_in_Healthcare_with_Retrieval_Augmented_Generative_AI_Chatbots.pdf\")\n",
        "clean_text = preprocess_text(paper_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "JvzzFHgcaIJf",
        "outputId": "541de24b-ac60-4bb0-b226-06651916c400"
      },
      "outputs": [],
      "source": [
        "# Install: pip install openai transformers\n",
        "from openai import OpenAI\n",
        "import transformers\n",
        "\n",
        "client = OpenAI(api_key='API-KEY')\n",
        "\n",
        "def summarize_with_gpt4(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Summarize this research paper for a non-expert audience. Highlight key contributions and methods.\"},\n",
        "            {\"role\": \"user\", \"content\": text[:30000]}  # Truncate to fit context window\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def extract_key_concepts(text):\n",
        "    # Use a pre-trained NLP model\n",
        "    nlp = transformers.pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "    entities = nlp(text)\n",
        "    keywords = [entity[\"word\"] for entity in entities if entity[\"entity\"] in [\"B-ORG\", \"B-MISC\"]]\n",
        "    return list(set(keywords))\n",
        "\n",
        "# Example usage:\n",
        "summary = summarize_with_gpt4(clean_text)\n",
        "keywords = extract_key_concepts(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nps-GCAZbASe"
      },
      "outputs": [],
      "source": [
        "def simplify_jargon(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Replace technical terms with simple analogies. Example: 'convolutional neural network' → 'an AI that detects patterns in images like a human eye'\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_analogy(concept):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Create a relatable analogy for this concept.\"},\n",
        "            {\"role\": \"user\", \"content\": concept}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example:\n",
        "simplified_text = simplify_jargon(summary)\n",
        "analogy = generate_analogy(\"Generative Adversarial Networks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BReGY2LUbWr7",
        "outputId": "02d9e5fc-e50d-4cfb-f977-276327214c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This study introduces a new method to make healthcare more efficient through the use of smart technologies. Even though technology use in healthcare has been on the rise, it hasn't always led to making work easier or faster, a predicament often coined as the \"productivity puzzle\".\n",
            "\n",
            "The researchers built a smart chatbot system that can create summaries of doctor-patient discussions, provide tentative diagnoses, and even gauge how a patient is feeling emotionally. Think of it as a scribe and an assistant who takes notes during the consultation, collects clues to pinpoint potential health issues, and assesses a patient's mood - all to help make responses more personal and meaningful.\n",
            "\n",
            "This system uses advanced language understanding techniques and pulls from a variety of different sources to provide accurate health-related assistance. It can help summarize patient discussions, assist in identifying potential illnesses, and understand a patient's emotional state, all with the aim of making patient involvement more effective and work processes more efficient.\n",
            "\n",
            "To show what this system can do, the researchers used it on a test health data set and found that it could properly summarize consultations, predict illnesses, and understand emotions. They expect that their systems could help solve the productivity puzzle in healthcare and hope to improve on them in future studies.\n"
          ]
        }
      ],
      "source": [
        "print(simplified_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qRUENV3cioV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE09QUm_b-BW",
        "outputId": "3a4bd3ae-7f15-417d-e141-3954fb337ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This research paper presents a new framework to improve productivity in healthcare through the application of artificial intelligence (AI). AI has been increasingly used in the healthcare sector, but despite many advances, there are still challenges, often referred to as the \"productivity paradox\", as increased investment in technology hasn’t always led to improved productivity.\n",
            "\n",
            "The researchers developed a Retrieval Augmented Generative AI Chatbot framework leveraging a type of AI known as Generative AI. The framework utilizes AI tools to create consultation summaries, diagnostic insights, and emotional assessments of patients, providing more contextually appropriate responses. \n",
            "\n",
            "The proposed framework utilizes large-scale language models and draws from diverse external resources to provide accurate medical services. It includes features for conversational summary of patient interactions, a section for disease diagnosis, and an emotion detection module to help identify the emotional states of patients, all aiming to improve patient engagement and workflow efficiency.\n",
            "\n",
            "The researchers also demonstrated the capabilities of this framework using a sample healthcare dataset and showed that it could effectively summarize consultations, predict diseases, and detect emotions. The researchers believe that their framework could help address the productivity paradox in healthcare and plan to enhance its capabilities in future research endeavours.\n"
          ]
        }
      ],
      "source": [
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1D4AQyjcVIB"
      },
      "outputs": [],
      "source": [
        "def generate_video_script(summary: str, analogy: str, video_type) -> str:\n",
        "    # Define structure based on video type\n",
        "    if video_type == \"reel\":\n",
        "        structure = \"\"\"\n",
        "        - Hook (15 seconds): Grab attention with a surprising fact/question\n",
        "        - Problem (30 seconds): Explain the research gap\n",
        "        - Analogy (35 seconds): Simplify using {}\n",
        "        - Impact (30 seconds): Why this matters\n",
        "        - Call-to-action (15 seconds)\n",
        "        \"\"\".format(analogy)\n",
        "    else:  # 5-minute YouTube video\n",
        "        structure = \"\"\"\n",
        "        - Intro (30s): Context + thesis\n",
        "        - Methodology (90s): Non-technical explanation\n",
        "        - Key Findings (90s): Visualized results\n",
        "        - Real-World Example (60s): {}\n",
        "        - Conclusion (30s)\n",
        "        \"\"\".format(analogy)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"Create a {video_type} script using this structure: {structure}\"},\n",
        "            {\"role\": \"user\", \"content\": summary}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usage:\n",
        "video_script = generate_video_script(simplified_text, analogy,video_type=\"youtube\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcsClLhDdbKz",
        "outputId": "a68df1c1-1f68-4b00-8ef6-c47ad5bcbe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Intro (30s): \n",
            "\n",
            "Hey there, friends! Today, we are diving deep into an innovative solution to a problem plaguing the healthcare industry - the productivity puzzle. So, healthcare technology, while advancing rapidly, isn't able to deliver on increased efficiency. We're exploring a promising system that works like a super-intelligent combo of trivia master and detective Sherlock Holmes to facilitate better healthcare services.\n",
            "\n",
            "- Methodology (90s):\n",
            "\n",
            "To understand this better, the researchers developed this system based on three major aspects. Picture yourself having a discussion with your patient. An AI buddy, the first part of the system, is there taking notes, compressing the lengthy conversation into an easy-to-understand summary. This is sort of like shorthand for medical consultations.\n",
            "\n",
            "Next up, we have a disease detective. This part of the system utilizes an algorithm that scans health reports and, similar to observant Sherlock Holmes, spots patterns that hint at potential diseases, somewhat like how Google's health tools work, but with a twist.\n",
            "\n",
            "Finally, an emotion reader comes into play. This AI detects the emotional state of patients from their dialogues, improving healthcare providers’ understanding of patients. This has been made possible by a new AI model that's been developed from scratch.\n",
            "\n",
            "- Key Findings (90s): \n",
            "\n",
            "The harmonious teamwork of this trivia-master and detective Sherlock Holmes-like system resulted in dramatic improvements in healthcare services. Its intelligent note-taking, Sherlock-esque diagnostic deductions, and emotion sensing from conversations, all based on data samples, lead to faster and appropriate decision-making, thereby robustly addressing the productivity puzzle.\n",
            "\n",
            "- Real-World Example (60s): \n",
            "\n",
            "Let's imagine the Generative Adversarial Network (GAN) setup here, where the generator is like a counterfeiter trying to craft fake currency and avoid detection. The discriminator, in this case, is like the vigilant cop tirelessly working to identify fake from real currency. They're continually upskilling themselves in this virtual cat and mouse game, which is intuitive of how this healthcare detective system responds to patient data and their conversations.\n",
            "\n",
            "- Conclusion (30s): \n",
            "\n",
            "In sum, the next steps for this awesome system involve integrating a wider variety of data and deploying it in real-life healthcare environments. By doing so, we are a step closer toward leveraging AI for refined healthcare services and tackling the productivity puzzle. Stay tuned for more exciting updates on this!\n"
          ]
        }
      ],
      "source": [
        "print(video_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VczH4rJfbX7",
        "outputId": "7065fad2-b9bf-4a64-8cb5-d4999179e00a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-36-e5b36701095c>:7: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_narration(script: str, output_path: str = \"narration.mp3\"):\n",
        "    response = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"nova\",  # Most expressive voice\n",
        "        input=script\n",
        "    )\n",
        "    response.stream_to_file(output_path)\n",
        "    return output_path\n",
        "\n",
        "# Generate audio narration\n",
        "audio_file = generate_narration(video_script)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Xnw5myh4SW",
        "outputId": "b8bf6238-7f29-42ce-8d8f-1df9218936ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video explainer_reel.mp4.\n",
            "MoviePy - Writing audio in explainer_reelTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video explainer_reel.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready explainer_reel.mp4\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
        "import math\n",
        "\n",
        "def create_video(image_paths: list, audio_path: str, output: str = \"output.mp4\"):\n",
        "    # Calculate scene durations\n",
        "    audio_clip = AudioFileClip(audio_path)\n",
        "    total_duration = audio_clip.duration\n",
        "    per_scene_duration = total_duration / len(image_paths)\n",
        "\n",
        "    # Create video clips\n",
        "    clips = []\n",
        "    for img in image_paths:\n",
        "        clip = ImageSequenceClip([img], durations=[per_scene_duration])\n",
        "        clips.append(clip)\n",
        "\n",
        "    final_video = concatenate_videoclips(clips)\n",
        "    final_video = final_video.set_audio(audio_clip)\n",
        "\n",
        "    # Format for vertical (reel) or horizontal (YouTube)\n",
        "    if len(image_paths[0].split(\"_\")) > 1 and \"reel\" in image_paths[0]:\n",
        "        final_video = final_video.resize(height=1920).crop(x1=240, width=1080)\n",
        "\n",
        "    final_video.write_videofile(output, fps=24)\n",
        "    return output\n",
        "\n",
        "# Assemble final video\n",
        "video_output = create_video(scene_images, audio_file, \"explainer_reel.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80z-fxttivkB",
        "outputId": "5452cf47-b6f1-464e-a77e-72c23eed2797"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "# 5. Podcast Generation\n",
        "# --------------------------\n",
        "def generate_podcast_script(summary: str, analogy: str) -> str:\n",
        "    \"\"\"Create conversational podcast script\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"Create a podcast dialogue:\n",
        "            - Host asks 5 questions\n",
        "            - Expert answers using analogy: {analogy}\n",
        "            - Keep answers under 120 seconds\"\"\"},\n",
        "            {\"role\": \"user\", \"content\": summary}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_podcast_audio(script: str, output: str = \"podcast.mp3\") -> str:\n",
        "    \"\"\"Generate multi-voice podcast audio\"\"\"\n",
        "    host_lines = [line.replace(\"Host: \", \"\")\n",
        "                 for line in script.split(\"\\n\") if line.startswith(\"Host:\")]\n",
        "    expert_lines = [line.replace(\"Expert: \", \"\")\n",
        "                   for line in script.split(\"\\n\") if line.startswith(\"Expert:\")]\n",
        "\n",
        "    # Generate voices\n",
        "    generate_narration(\"\\n\".join(host_lines), \"host_temp.mp3\", voice=\"nova\")\n",
        "    generate_narration(\"\\n\".join(expert_lines), \"expert_temp.mp3\", voice=\"shimmer\")\n",
        "\n",
        "    # Mix audio\n",
        "    host_audio = AudioSegment.from_file(\"host_temp.mp3\")\n",
        "    expert_audio = AudioSegment.from_file(\"expert_temp.mp3\")\n",
        "    combined = host_audio + AudioSegment.silent(500) + expert_audio\n",
        "    combined.export(output, format=\"mp3\")\n",
        "\n",
        "    # Cleanup\n",
        "    os.remove(\"host_temp.mp3\")\n",
        "    os.remove(\"expert_temp.mp3\")\n",
        "\n",
        "    return output\n",
        "podcast_script = generate_podcast_script(summary,analogy)\n",
        "podcast_file = generate_podcast_audio(podcast_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtZl6vUci4Tz"
      },
      "outputs": [],
      "source": [
        "def full_pipeline(pdf_path: str, output_format: str = \"video\"):\n",
        "    # Text extraction\n",
        "    raw_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Analysis and simplification\n",
        "    summary = summarize_with_gpt4(raw_text)\n",
        "    simplified = simplify_jargon(summary)\n",
        "    analogy = generate_analogy(extract_key_concepts(raw_text)[0])\n",
        "\n",
        "    # Content creation\n",
        "    if output_format == \"video\":\n",
        "        script = generate_video_script(simplified, analogy)\n",
        "        images = generate_scene_images(script)\n",
        "        audio = generate_narration(script)\n",
        "        output = create_video(images, audio)\n",
        "    elif output_format == \"podcast\":\n",
        "        script = generate_podcast_script(simplified)\n",
        "        output = generate_podcast_audio(script)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Example usage:\n",
        "final_output = full_pipeline(\"research_paper.pdf\", output_format=\"video\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IryyqHgppLLn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdADGPGmpp-P",
        "outputId": "5ab4b2d9-9e76-42df-dfba-2a83d6e5500b"
      },
      "outputs": [],
      "source": [
        "!pip install openai PyPDF2 pdf2image pytesseract transformers moviepy pydub requests pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0M69DmOpwKj",
        "outputId": "2f780f6e-bc85-47c7-d18a-1d22fdbba2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Podcast Script:\n",
            "Host: What exactly is Generative Adversarial Network, and what role does it play in this AI research?\n",
            "Expert: Well, a Generative Adversarial Network (GAN) is kind of like a duo of a counterfeiter and a cop in a game of cat and mouse. The counterfeiter, also known as the generator, creates fake currency and tries to pass it off as real, while the cop, also known as the discriminator is working hard to discern which currency is real and which is fake. This constant cat and mouse game helps both the generator and discriminator to continually improve, much like GANs in machine learning improve to provide more accurate results.\n",
            "\n",
            "Host: You mentioned a productivity paradox in healthcare settings as the motivation behind this project. Could you explain this further?\n",
            "Expert: Of course. The productivity paradox refers to the scenario where despite investing a lot in AI and technology, the efficiency in the healthcare workspace doesn't see much of an improvement. It's like pouring water into a leaky bucket, you're putting in resources, but the results don't match your expectations. This framework aims to seal the leaks, so to speak, by making interactions more efficient via AI.\n",
            "\n",
            "Host: How does the conversation summarization module work in this framework?\n",
            "Expert: So, picture this - you're in a meeting and your job is to take minutes, but the conversation is quite complex and long-winded. You really wish you had tool that could make sense of it and give you just the relevant bullet points. That's essentially what the conversation summarization module does. It uses LangChain to extract key points from lengthy telehealth conversations, turning them into concise, clear notes. \n",
            "\n",
            "Host: The research also discusses a disease diagnosis module. Please tell us a bit about that.\n",
            "Expert: Think of the disease diagnosis module like a detective, the Sherlock Holmes of patient data if you will. It uses machine learning and AI to piece together clues from a patient's health record and other data to predict potential disease states. It's like the way a detective uses clues to solve a mystery, with machine learning acting as the magnifying glass.\n",
            "\n",
            "Host: Lastly, let's touch upon the emotion detection module. How does it function?\n",
            "Expert: The emotion detection module works a bit like a human therapist. It's designed to pick up on the emotional state of patients based on their conversation data, much like how a therapist reads the emotional cues of their patients during a session. It gives the system a more human touch, allowing it to provide more personalised care.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-43-dc86e1bb84aa>:86: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(output_path)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Podcast generated at: podcast5.mp3\n"
          ]
        }
      ],
      "source": [
        "def generate_podcast_script(summary: str, analogy: str) -> str:\n",
        "    \"\"\"Create conversational podcast script with alternating Q&A\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"Create a podcast script with 5 question/answer pairs. Follow this exact format:\n",
        "\n",
        "            Host: [Question 1]\n",
        "            Expert: [Answer 1 using analogy: {analogy}]\n",
        "            Host: [Question 2]\n",
        "            Expert: [Answer 2  using analogy: {analogy}]\n",
        "            Host: [Question 3]\n",
        "            Expert: [Answer 3]\n",
        "            Host: [Question 4]\n",
        "            Expert: [Answer 4]\n",
        "            Host: [Question 5]\n",
        "            Expert: [Answer 5]\n",
        "\n",
        "            Keep answers under 100 words. Use natural conversation flow.\"\"\"},\n",
        "            {\"role\": \"user\", \"content\": summary}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_podcast_audio(script: str, output: str = \"podcast5.mp3\") -> str:\n",
        "    \"\"\"Generate conversational audio with alternating voices\"\"\"\n",
        "    from pydub import AudioSegment\n",
        "\n",
        "    # Split script into lines while preserving order\n",
        "    lines = [line.strip() for line in script.split(\"\\n\") if line.strip()]\n",
        "    combined_audio = AudioSegment.silent(duration=0)\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith(\"Host:\"):\n",
        "            text = line.replace(\"Host: \", \"\")\n",
        "            temp_file = \"host_temp.mp3\"\n",
        "            generate_narration(text, temp_file, voice=\"nova\")\n",
        "        elif line.startswith(\"Expert:\"):\n",
        "            text = line.replace(\"Expert: \", \"\")\n",
        "            temp_file = \"expert_temp.mp3\"\n",
        "            generate_narration(text, temp_file, voice=\"shimmer\")\n",
        "        else:\n",
        "            continue  # Skip malformed lines\n",
        "\n",
        "        # Add pause between lines\n",
        "        audio_segment = AudioSegment.from_file(temp_file)\n",
        "        combined_audio += audio_segment + AudioSegment.silent(duration=500)\n",
        "        os.remove(temp_file)  # Clean up temp file\n",
        "\n",
        "    # Add intro/outro music\n",
        "    intro_music = AudioSegment.silent(duration=1000)  # Replace with actual music file\n",
        "    outro_music = AudioSegment.silent(duration=1000)\n",
        "    final_audio = intro_music + combined_audio + outro_music\n",
        "\n",
        "    final_audio.export(output, format=\"mp3\")\n",
        "    return output\n",
        "\n",
        "# Example generated script format:\n",
        "\"\"\"\n",
        "Host: Why is this research important for regular people?\n",
        "Expert: Think of it like teaching computers to see patterns the way humans do...\n",
        "Host: How does the technology actually work?\n",
        "Expert: Imagine two artists competing...\n",
        "Host: What real-world applications could this have?\n",
        "Expert: We're already seeing uses in...\n",
        "\"\"\"\n",
        "\n",
        "podcast_script = generate_podcast_script(summary, analogy)\n",
        "print(\"Podcast Script:\")\n",
        "print(podcast_script)\n",
        "\n",
        "podcast_file = generate_podcast_audio(podcast_script)\n",
        "print(f\"Podcast generated at: {podcast_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2647fjRduwgp"
      },
      "outputs": [],
      "source": [
        "def generate_podcast_script(summary: str, analogy: str, key_concepts: list) -> str:\n",
        "    \"\"\"Generate podcast script covering full paper approach\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"\"\"Create a detailed podcast script covering the ENTIRE research paper. Include:\n",
        "\n",
        "            1. Paper's core problem/question\n",
        "            2. Methodology/approach used\n",
        "            3. Key technical innovations\n",
        "            4. Experimental setup\n",
        "            5. Main findings\n",
        "            6. Real-world implications\n",
        "\n",
        "            Format STRICTLY as:\n",
        "            [Intro music]\n",
        "            Host: Welcome! Today we're discussing [paper title]. Our guest is [imaginary expert name].\n",
        "            Host: What problem were you trying to solve?\n",
        "            Expert: [2-3 sentence answer using analogy: {analogy}]\n",
        "            Host: How did you approach this?\n",
        "            Expert: [Detailed methodology explanation using analogy: {analogy}]\n",
        "            Host: What was the most innovative technical aspect?\n",
        "            Expert: [Technical breakdown with example]\n",
        "            Host: How did you validate your results?\n",
        "            Expert: [Experiment description]\n",
        "            Host: What surprised you most?\n",
        "            Expert: [Key findings discussion]\n",
        "            Host: Where could this be applied practically?\n",
        "            Expert: [Real-world applications]\n",
        "            [Outro music]\n",
        "\n",
        "            Use concepts: {', '.join(key_concepts)}. Keep answers conversational.\"\"\"},\n",
        "            {\"role\": \"user\", \"content\": summary}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_complete_podcast(pdf_path: str) -> str:\n",
        "    \"\"\"End-to-end podcast generation about full paper\"\"\"\n",
        "    # Extract and process content\n",
        "    raw_text = extract_text_from_pdf(pdf_path)\n",
        "    summary = summarize_with_gpt4(raw_text)\n",
        "    simplified = simplify_jargon(summary)\n",
        "    key_concepts = extract_key_concepts(raw_text)\n",
        "    analogy = generate_analogy(key_concepts[0])\n",
        "\n",
        "    # Generate podcast components\n",
        "    script = generate_podcast_script(summary, analogy, key_concepts)\n",
        "    print(\"Generated Script:\\n\", script)\n",
        "\n",
        "    # Audio production\n",
        "    return generate_podcast_audio(script)\n",
        "\n",
        "# Enhanced audio generation with pacing\n",
        "def generate_podcast_audio(script: str, output: str = \"full_paper_podcast.mp3\") -> str:\n",
        "    \"\"\"Generate professional podcast audio with pacing\"\"\"\n",
        "    from pydub import AudioSegment\n",
        "    from pydub.effects import normalize\n",
        "\n",
        "    # Split script into components\n",
        "    segments = []\n",
        "    current_speaker = None\n",
        "    current_text = []\n",
        "\n",
        "    for line in script.split(\"\\n\"):\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"Host:\") or line.startswith(\"Expert:\"):\n",
        "            if current_speaker:\n",
        "                segments.append((current_speaker, \"\\n\".join(current_text)))\n",
        "            current_speaker = \"Host\" if line.startswith(\"Host:\") else \"Expert\"\n",
        "            current_text = [line.split(\": \", 1)[1]]\n",
        "        elif line and current_speaker:\n",
        "            current_text.append(line)\n",
        "\n",
        "    if current_text:\n",
        "        segments.append((current_speaker, \"\\n\".join(current_text)))\n",
        "\n",
        "    # Generate audio with professional pacing\n",
        "    combined = AudioSegment.silent(duration=1000)  # Intro silence\n",
        "    for speaker, text in segments:\n",
        "        temp_file = f\"{speaker}_temp.mp3\"\n",
        "        voice = \"nova\" if speaker == \"Host\" else \"shimmer\"\n",
        "\n",
        "        # Generate speech with natural pauses\n",
        "        generate_narration(text, temp_file, voice=voice)\n",
        "        audio = AudioSegment.from_file(temp_file)\n",
        "\n",
        "        # Add subtle effects\n",
        "        audio = normalize(audio).fade_in(200).fade_out(200)\n",
        "        if speaker == \"Expert\":\n",
        "            audio = audio.low_pass_filter(1500)  # Differentiate voices\n",
        "\n",
        "        combined += audio + AudioSegment.silent(750)  # Natural pause\n",
        "        os.remove(temp_file)\n",
        "\n",
        "    # Add intro/outro music (replace with actual files)\n",
        "    combined = AudioSegment.silent(2000) + combined + AudioSegment.silent(2000)\n",
        "    combined.export(output, format=\"mp3\")\n",
        "    return output\n",
        "\n",
        "# Usage\n",
        "podcast_path = generate_complete_podcast(\"research_paper.pdf\")\n",
        "print(f\"Full paper podcast generated at: {podcast_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
